{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training and Validation Set data preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from transformers import AutoTokenizer\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a919c0eba7e145198fb132345ef15d50",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (‚Ä¶)okenizer_config.json:   0%|          | 0.00/1.43k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "471f697bd3014e90a3cca3a471559e12",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading tokenizer.model:   0%|          | 0.00/493k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e7c2416a832c47428096f78e36b1e183",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (‚Ä¶)/main/tokenizer.json:   0%|          | 0.00/1.80M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8bd5b5da1aae4975a85843402ad8551e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (‚Ä¶)in/added_tokens.json:   0%|          | 0.00/42.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0115808c178443d2aef1fd0738c128d5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (‚Ä¶)cial_tokens_map.json:   0%|          | 0.00/168 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model_name = \"HuggingFaceH4/zephyr-7b-beta\"\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading the RAW Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"rogers_data/dataset.csv\", usecols=['company_key', 'message_order', 'case_id', 'text', 'response_text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['company_key', 'case_id', 'text', 'response_text', 'message_order'], dtype='object')"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "57078"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df[\"case_id\"].unique().tolist())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Grouping by the conversation ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "nf = df.groupby(by=[\"case_id\"], group_keys=False).apply(lambda x: x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "nf.dropna(subset=['text', 'response_text'], how='all', inplace=True)\n",
    "\n",
    "nf['MessageDiff'] = nf.groupby('case_id')['message_order'].diff()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>company_key</th>\n",
       "      <th>case_id</th>\n",
       "      <th>text</th>\n",
       "      <th>response_text</th>\n",
       "      <th>message_order</th>\n",
       "      <th>MessageDiff</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>rogers</td>\n",
       "      <td>10617686</td>\n",
       "      <td>@Rogers @top_employers @RogersCareers Please p...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>rogers</td>\n",
       "      <td>10617686</td>\n",
       "      <td>NaN</td>\n",
       "      <td>We appreciate you taking the time to bring you...</td>\n",
       "      <td>6</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>rogers</td>\n",
       "      <td>16892578</td>\n",
       "      <td>This shirt speaks volumes. üé§ You saw the power...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>rogers</td>\n",
       "      <td>16892578</td>\n",
       "      <td>Hey! Guess what? Fido‚Äôs on TikTok! Something b...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>rogers</td>\n",
       "      <td>16892578</td>\n",
       "      <td>üè≥Ô∏è‚Äç‚ößÔ∏èToday is #TransDayOfVisibility! We‚Äôre pro...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  company_key   case_id                                               text  \\\n",
       "0      rogers  10617686  @Rogers @top_employers @RogersCareers Please p...   \n",
       "2      rogers  10617686                                                NaN   \n",
       "3      rogers  16892578  This shirt speaks volumes. üé§ You saw the power...   \n",
       "4      rogers  16892578  Hey! Guess what? Fido‚Äôs on TikTok! Something b...   \n",
       "5      rogers  16892578  üè≥Ô∏è‚Äç‚ößÔ∏èToday is #TransDayOfVisibility! We‚Äôre pro...   \n",
       "\n",
       "                                       response_text  message_order  \\\n",
       "0                                                NaN              1   \n",
       "2  We appreciate you taking the time to bring you...              6   \n",
       "3                                                NaN              1   \n",
       "4                                                NaN              3   \n",
       "5                                                NaN              5   \n",
       "\n",
       "   MessageDiff  \n",
       "0          NaN  \n",
       "2          5.0  \n",
       "3          NaN  \n",
       "4          2.0  \n",
       "5          2.0  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nf.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extract conversations from the RAW Dataset and preparing the prompts according to Chat Template of LLMs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def extract_conversation(df):\n",
    "    conv = {\"customer\": [], \"agent\": []}\n",
    "    order = 0\n",
    "    for index, col in df.iterrows():\n",
    "        text = col[\"text\"]\n",
    "        response = col[\"response_text\"]\n",
    "        if type(text) == float:\n",
    "            resp = response, order\n",
    "            conv[\"agent\"].append(resp)\n",
    "        if type(response) == float:\n",
    "            conv[\"customer\"].append(text)\n",
    "            order += 1\n",
    "    return conv\n",
    "\n",
    "\n",
    "def prepare_prompt(conversation: dict):\n",
    "    messages = []\n",
    "    count = 0\n",
    "    for user_message in conversation[\"customer\"]:\n",
    "        count += 1\n",
    "        cust_dict = {\"role\": \"user\", \"content\": user_message}\n",
    "        messages.append(cust_dict)\n",
    "        for response in conversation[\"agent\"]:\n",
    "            if response[1] == count:\n",
    "                response_dict = {\"role\": \"assistant\", \"content\": response[0]}\n",
    "                messages.append(response_dict)\n",
    "    return messages\n",
    "\n",
    "\n",
    "def extract_and_prepare_text(data_df, conversation_ids):\n",
    "    prompts, conv_id = [], []\n",
    "    for conversation_id in conversation_ids:\n",
    "        sample = data_df[data_df[\"case_id\"] == conversation_id]\n",
    "        conversation = extract_conversation(sample)\n",
    "        instruction = prepare_prompt(conversation)\n",
    "        prompts.append(instruction)\n",
    "        conv_id.append(conversation_id)\n",
    "    return prompts, conv_id\n",
    "\n",
    "\n",
    "def prepare_df_from_prompts(conv_id, prompts):\n",
    "    data_dict = {\"conversation_id\": conv_id, \"instruction\": prompts}\n",
    "    processed_df = pd.DataFrame(data_dict)\n",
    "    return processed_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "nf_conv_ids = nf[\"case_id\"].unique().tolist()\n",
    "\n",
    "prompts, convs = extract_and_prepare_text(nf, nf_conv_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "system_prompt = {\"role\": \"system\",\n",
    "                 \"content\": \"You are a helpful assistant. Your task is to help an assistant to write responses quickly for a customer-agent conversation based on the coversation history\"}\n",
    "\n",
    "for prompt in prompts:\n",
    "    prompt.insert(0, system_prompt)\n",
    "\n",
    "formatted_prompts = []\n",
    "for prompt in prompts:\n",
    "    new = tokenizer.apply_chat_template(prompt, tokenize=False, add_generation_prompt=False)\n",
    "    if new.rfind(\"<|assistant|>\") != -1:\n",
    "        formatted_prompts.append(new)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split the data into train, validation and test sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train dataset 25419, and Validation dataset 2825, and Test dataset: 3139\n"
     ]
    }
   ],
   "source": [
    "train_data, test_ds = train_test_split(formatted_prompts, shuffle=False, test_size=0.1, random_state=42)\n",
    "train_ds, val_ds = train_test_split(train_data, shuffle=False, test_size=0.1, random_state=42)\n",
    "print(f\"Train dataset {len(train_ds)}, and Validation dataset {len(val_ds)}, and Test dataset: {len(test_ds)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load the formatted prompts into Dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_df = pd.DataFrame(train_ds, columns=[\"text\"])\n",
    "val_df = pd.DataFrame(val_ds, columns=[\"text\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save the train, test and validation sets as CSV files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_df = train_df[10:]\n",
    "\n",
    "train_df.to_csv(\"rogers_data/rogers_train_df.csv\", index=False)\n",
    "val_df.to_csv(\"rogers_data/rogers_val_df.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test data preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "save_prompt, targets = [], []\n",
    "for test_prompt in test_ds:\n",
    "    find = test_prompt.find(\"<|assistant|>\")\n",
    "    rfind = test_prompt.rfind(\"<|assistant|>\")\n",
    "    if find == rfind:\n",
    "        idx = find + len(\"<|assistant|>\")\n",
    "        test_text = test_prompt[:idx]\n",
    "        save_prompt.append(test_text)\n",
    "        targets.append(test_prompt[idx+1:])\n",
    "    elif rfind > find:\n",
    "        idx = rfind + len(\"<|assistant|>\")\n",
    "        test_text = test_prompt[:idx]\n",
    "        save_prompt.append(test_text)\n",
    "        targets.append(test_prompt[idx+1:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "test_data = {\"text\": save_prompt, \"targets\": targets}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "test_df = pd.DataFrame(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>targets</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>&lt;|system|&gt;\\nYou are a helpful assistant. Your ...</td>\n",
       "      <td>With the 'Silence Unknown Callers' feature, it...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>&lt;|system|&gt;\\nYou are a helpful assistant. Your ...</td>\n",
       "      <td>I do see the request has been sent! The number...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>&lt;|system|&gt;\\nYou are a helpful assistant. Your ...</td>\n",
       "      <td>I can go ahead and document this offer on your...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>&lt;|system|&gt;\\nYou are a helpful assistant. Your ...</td>\n",
       "      <td>You're truly welcome &lt;PERSON&gt;. &lt;PERSON&gt; happy ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>&lt;|system|&gt;\\nYou are a helpful assistant. Your ...</td>\n",
       "      <td>The pleasure was all mine! Please, don't hesit...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  \\\n",
       "0  <|system|>\\nYou are a helpful assistant. Your ...   \n",
       "1  <|system|>\\nYou are a helpful assistant. Your ...   \n",
       "2  <|system|>\\nYou are a helpful assistant. Your ...   \n",
       "3  <|system|>\\nYou are a helpful assistant. Your ...   \n",
       "4  <|system|>\\nYou are a helpful assistant. Your ...   \n",
       "\n",
       "                                             targets  \n",
       "0  With the 'Silence Unknown Callers' feature, it...  \n",
       "1  I do see the request has been sent! The number...  \n",
       "2  I can go ahead and document this offer on your...  \n",
       "3  You're truly welcome <PERSON>. <PERSON> happy ...  \n",
       "4  The pleasure was all mine! Please, don't hesit...  "
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Save the test set to a csv file\n",
    "\n",
    "test_df.to_csv(\"rogers_data/rogers_test_df.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def format_prompt(customer, agent):\n",
    "#     system_prompt = \"\"\"You are a text completion assistant. \\\n",
    "#     Given the conversation between Human and Assistant your task is to help assistant to complete his response.\"\"\"\n",
    "#     prompt = \"<s>\"\n",
    "#     prompt += f\"[INST] {system_prompt} \"\n",
    "#     i = 0\n",
    "#     for cust, agnt in zip(customer, agent):\n",
    "#         if i != 0 and type(cust) == str and cust != '':\n",
    "#             prompt += f\"[INST] {cust} [/INST]\"\n",
    "#             prompt += f\" {agnt} </s>\"\n",
    "#         if i == 0:\n",
    "#             prompt += f\"{cust} [/INST]\"\n",
    "#             prompt += f\" {agnt} </s>\"\n",
    "#         i += 1\n",
    "#     return prompt\n",
    "\n",
    "\n",
    "# def format_new_prompt(customer, agent):\n",
    "#     prompt = \"\"\n",
    "#     for cust, agnt in zip(customer, agent):\n",
    "#         if type(cust) == str and cust != ' ':\n",
    "#             prompt += f\"### Human: {cust}.\"\n",
    "#             prompt += f\"### Assistant: {agnt}.\"\n",
    "#     return prompt\n",
    "\n",
    "# def prepare_test_chat_template(chat_history):\n",
    "#     chat = []\n",
    "#     convs = {\"history\": [], \"target_utterance\": []}\n",
    "#     i = 0\n",
    "#     for user, assistant in zip(chat_history[\"customer\"], chat_history[\"agent\"]):\n",
    "#         if i != 0 and type(user) == str and user == str(\"\"):\n",
    "#             chat.append({\"role\": \"user\", \"content\": user.strip(\" \")})\n",
    "#             chat_template = tokenizer.apply_chat_template(chat, tokenize=False)\n",
    "#             chat.append({\"role\": \"assistant\", \"content\": assistant})\n",
    "#             convs[\"history\"].append(chat_template)\n",
    "#             convs[\"target_utterance\"].append(assistant)\n",
    "#         if i == 0:\n",
    "#             chat.append({\"role\": \"user\", \"content\": user.strip(\" \")})\n",
    "#             chat_template = tokenizer.apply_chat_template(chat, tokenize=False)\n",
    "#             chat.append({\"role\": \"assistant\", \"content\": assistant})\n",
    "#             convs[\"history\"].append(chat_template)\n",
    "#             convs[\"target_utterance\"].append(assistant)\n",
    "#         i += 1\n",
    "#     return convs\n",
    "\n",
    "\n",
    "# def extract_conversation(df):\n",
    "#     conv = df[\"last_conversation\"].tolist()\n",
    "#     target = df[\"target_utterance\"].tolist()\n",
    "#     idx = [i for i in range(len(conv))]\n",
    "\n",
    "#     chat = []\n",
    "#     last = conv.copy()\n",
    "#     target = target.copy()\n",
    "\n",
    "#     try:\n",
    "#         for ids, last_conv, target_utter in zip(idx, conv, target):\n",
    "#             if ids == 0:\n",
    "#                 chat.append(last_conv)\n",
    "#                 chat.append(target_utter)\n",
    "#             if ids >= 1:\n",
    "#                 if type(last[ids]) == str and last[ids] != '':\n",
    "#                 idx = len(target[ids-1]) + last[ids].index(target[ids-1]) + 1\n",
    "#                 updated_conv = last_conv[idx:]\n",
    "#                 chat.append(updated_conv)\n",
    "#                 chat.append(target_utter)\n",
    "#     except ValueError:\n",
    "#         pass\n",
    "#     return chat\n",
    "\n",
    "\n",
    "# def prepare_dialogue(example, tokenizer):\n",
    "#     text = \"\"\n",
    "#     for idx, msg in enumerate(example):\n",
    "#         if idx % 2 == 0:\n",
    "#             text += f\"<|user|>\\n{msg}{tokenizer.eos_token}\\n\"\n",
    "#         else:\n",
    "#             text += f\"<|assistant|>\\n{msg}{tokenizer.eos_token}\\n\"\n",
    "#     return text"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_pytorch_p310",
   "language": "python",
   "name": "conda_pytorch_p310"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
